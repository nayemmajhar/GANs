{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyGANs",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzUuX48-Ce1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtxURg18FYnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorboardX  # need to install in google colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe0nTGWfCuAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%autoreload 2\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "!cp \"/content/drive/My Drive/utils.py\" . # need to upload utils.py in google drive to import in google colab\n",
        "from utils import Logger\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkxRJFzT3o3w",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db4Ri2MAFeG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_FOLDER = './torch_data/VGAN/MNIST'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlDhwnxAFkkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mnist_data():\n",
        "    compose = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((.5,), (.5,))\n",
        "        ])\n",
        "    out_dir = '{}/dataset'.format(DATA_FOLDER)\n",
        "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZDSBi7KGAz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "data = mnist_data()\n",
        "# Create loader with data, so that we can iterate over it\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
        "# Num batches\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88KQCoGX4Am0",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic_WSOZRGG08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 784\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pbByUiQ7slf",
        "colab_type": "text"
      },
      "source": [
        "## Generator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYHw-egOGKsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        n_out = 784\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMz2KH9PGNkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = DiscriminatorNet()\n",
        "generator = GeneratorNet()\n",
        "if torch.cuda.is_available():\n",
        "    discriminator.cuda()\n",
        "    generator.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiR0F72M77pr",
        "colab_type": "text"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2GzH5RPGPhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizers\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "\n",
        "# Loss function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# Number of steps to apply to the discriminator\n",
        "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
        "# Number of epochs\n",
        "num_epochs = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8vnkdop-Zb4",
        "colab_type": "text"
      },
      "source": [
        "## Create Random Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpViwdCC4yp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Noise\n",
        "def noise(size):\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    if torch.cuda.is_available(): return n.cuda() \n",
        "    return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8xtP0fx7_wY",
        "colab_type": "text"
      },
      "source": [
        "## Models for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnnLEMShGSIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def real_data_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data\n",
        "\n",
        "def fake_data_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT3EkcyjGWRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error\n",
        "    return error_real + error_fake, prediction_real, prediction_fake\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    # 2. Train Generator\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
        "    error.backward()\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sk5uG7u_VVi",
        "colab_type": "text"
      },
      "source": [
        "## Reshape Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJEY0NIt4fL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def images_to_vectors(images):\n",
        "    return images.view(images.size(0), 784)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "    return vectors.view(vectors.size(0), 1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvr5GZHY_C1d",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Generate Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh1usBkBGaJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU90CEFw_Gz_",
        "colab_type": "text"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7naKOriKGeeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(images_to_vectors(real_batch))\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
        "                                                                real_data, fake_data)\n",
        "\n",
        "        # 2. Train Generator\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_batch.size(0)))\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "        # Log error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress\n",
        "        if (n_batch) % 100 == 0:\n",
        "            display.clear_output(True)\n",
        "            # Display Images\n",
        "            test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
        "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )\n",
        "        # Model Checkpoints\n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}